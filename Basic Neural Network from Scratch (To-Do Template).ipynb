{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Neural Network from Scratch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">## Objective: \n",
    "\n",
    "To understand and build a basic one hidden layer Neutral Network from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Approach : \n",
    "\n",
    "- **Getting the Dataset**\n",
    "- **Logistic Regression**\n",
    "- **Neural Network : Understanding**\n",
    "     \n",
    "       - Neural Network structure\n",
    "       - Activation functions : Softmax and Tanh and their necessity \n",
    "       - Weight factors and Bias \n",
    "       - Forward Propagation\n",
    "       - Back Propagation\n",
    "       - Shape of Vectors\n",
    "       - Differentiation\n",
    "       \n",
    "- **Implementation**\n",
    "\n",
    "       - Model Function\n",
    "       - Predict Function\n",
    "       - Loss Function\n",
    "\n",
    "- **Varying hidden layer nodes**\n",
    "- **Conclusion**\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Libraries** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.linear_model\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 8.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Plot_decision_boundary` function is defined to conveniently see the decision boundary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to plot a decision boundary.\n",
    "# If you don't fully understand this function don't worry, it just generates the contour plot below.\n",
    "def plot_decision_boundary(pred_func):\n",
    "    # Set min and max values and give it some padding\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    h = 0.01\n",
    "    # Generate a grid of points with distance h between them\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    # Predict the function value for the whole gid\n",
    "    Z = pred_func(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    # Plot the contour and training examples\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `1.` Getting the Dataset\n",
    "\n",
    "Dataset is generated using sklearn's built in methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x27c7e815d48>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate a dataset and plot it\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "np.random.seed(0)\n",
    "X, y = sklearn.datasets.make_moons(200, noise=0.20)\n",
    "plt.scatter(X[:,0], X[:,1], s=40, c=y, cmap=plt.cm.Spectral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset generated has two classes, plotted as red and blue points. You can think of the blue dots as male patients and the red dots as female patients, with the x- and y- axis being medical measurements.\n",
    "\n",
    "Your goal is to train a Machine Learning classifier that predicts the correct class (male or female) given the x- and y- coordinates. Note that the data is not linearly separable, a straight line cant be drawn that separates the two classes. This means that linear classifiers, such as Logistic Regression, won't be able to fit the data unless you hand-engineer non-linear features (such as polynomials) that work well for the given dataset.\n",
    "\n",
    "In fact, that's one of the major advantages of Neural Networks. You don't need to worry about feature engineering. The hidden layer of a neural network will learn features for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `2.` Logistic Regression: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand the problem better , try to implement a logistic regression first on the dataset and plot the decision boundary using the earlier defined function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK : Build a `logistic regression` model and fit it on the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE (~ 2 Lines of code)\n",
    "\n",
    "### END CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK : Plot the `Decision boundary` using the earlier defined function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the argument of lambda x: use the predict function of the earlier defined classifier that was fit on dataset\n",
    "\n",
    "### START CODE HERE (~2 Lines of code)\n",
    "#(Write code where '#' is given)\n",
    "\n",
    "plot_decision_boundary(lambda x: '# ')\n",
    "plt.title(\"Logistic Regression\")\n",
    "\n",
    "### END CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph shows the decision boundary learned by our Logistic Regression classifier. It separates the data as good as it can using a straight line, but it's unable to capture the \"moon shape\" of our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `3.`  Neural Networks : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.1` Neural Networks Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now build a 3-layer neural network with one input layer, one hidden layer, and one output layer. The number of nodes in the input layer is determined by the dimensionality of our data, 2. Similarly, the number of nodes in the output layer is determined by the number of classes we have, also 2. (Because we only have 2 classes we could actually get away with only one output node predicting 0 or 1, but having 2 makes it easier to extend the network to more classes later on). The input to the network will be x- and y- coordinates and its output will be two probabilities, one for class 0 (\"female\") and one for class 1 (\"male\"). It looks something like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.stack.imgur.com/iHDtO.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can choose the dimensionality (the number of nodes) of the hidden layer. The more nodes we put into the hidden layer the more complex functions we will be able fit. But higher dimensionality comes at a cost. First, more computation is required to make predictions and learn the network parameters. A bigger number of parameters also means that the model become more prone to overfitting the data.\n",
    "\n",
    "How to choose the size of the hidden layer? While there are some general guidelines and recommendations, it always depends on your specific problem and is more of an art than a science. Its best to play with the number of nodes in the hidden layer and see how it affects the output.\n",
    "\n",
    "You also need to pick an activation function for the hidden layer. The activation function transforms the inputs of the layer into its outputs.  Common chocies for activation functions are tanh, the sigmoid function, or ReLUs. Here you'll use tanh, which performs quite well in many scenarios. A nice property of these functions is that their derivate can be computed using the original function value. For example, the derivative of $\\tanh x$ is $1-\\tanh^2 x$. This is useful because it allows to compute $\\tanh x$ once and re-use its value later on to get the derivative.\n",
    "\n",
    "The network is desired to output probabilities thus the activation function for the output layer will be the softmax, which is simply a way to convert raw scores to probabilities. If you're familiar with the logistic function you can think of softmax as its generalization to multiple classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.2` Activation Functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Softmax :**\n",
    "<img src=\"https://miro.medium.com/max/1812/1*670CdxchunD-yAuUWdI7Bw.png\" widht=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where the function is defined as : \n",
    "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcSzssj62d-Ke7FH24hbFPlkQVrl9cnkoYSaSs-As9bA9k5LgdFf&usqp=CAU\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tanh :**\n",
    "<img src=\"https://machinelearningblogcom.files.wordpress.com/2017/11/bildschirmfoto-2017-11-10-um-12-20-57.png?w=428&h=237\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why are Activation Functions necessary?**\n",
    "\n",
    "If there were no activation function or just linear activation function then it would work same as a linear classifier/regressor and the models applications would be very limited and thus a nonlinear activation function is what really allows to fit nonlinear hypotheses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding the network**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input $x$ contains two attributes namely $x1$ and $x2$ and has $m$ number of training examples , in this dataset $m$ = 200. \n",
    "Neural networks are similar to logistic regression just that the latter is used for binary classification/regression and the former is used for multiclass classification/regression. Think of it this way that In logistic regression , attributes or inputs are given to a box or a node which multiplies the inputs with weight factors , adds bias and outputs the resultant similar to linear regression which is then transformed by a non linear activtion function , sigmoid in logistic regression to give the final output. Similarly , In neural networks this whole process happens alot of times , in this notebook with just one hidden layer the whole process occurs as many times as the number of nodes in the hidden layer , so each node's input-output can be visualised as logistic regression and many such singluar logistic regression units give birth to neural networks which shows generally why neural networks perform better than its singular counterpart. This whole process can be explained better with the following image :\n",
    "<img src=\"https://www.cntk.ai/jup/cntk103b_TwoFormsOfLR-v3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.3` Weight factors and Bias\n",
    "\n",
    "**Bias** : The term bias is used to adjust the final output matrix as the y-intercept does. For instance, in the classic equation, $y = mx + c$, if $c$ = 0, then the line will always pass through 0. Adding the bias term provides more flexibility and better generalisation to our Neural Network model.\n",
    "\n",
    "**Weight Factors** : Weight factors gives out the best linear combinations of attributes which would give the closest ouput\n",
    "\n",
    "Weight factors and Bias values are first randomly given and then adjusted through `Back Propaagtion` and `Gradient Descent` to find the optimum combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.4` Forward Propagation : How the network makes predictions\n",
    "\n",
    "The network makes predictions using forward propagation, which is just a bunch of matrix multiplications and the application of the activation function(s) as defined above. If $x$ is the 2-dimensional input to the network then predictions $\\hat{y}$ (also two-dimensional) can be calculated as follows:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "z_1 = xW_1 + b_1 \\\\ \n",
    "a_1 = \\tanh(z_1) \\\\\n",
    "z_2 = a_1W_2 + b_2 \\\\\n",
    "a_2 = \\hat{y} = \\mathrm{softmax}(z_2)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$z_i$ is the weighted sum of inputs of layer $i$ (bias included) so $z_1$ contains all the outputs from all the nodes in the first hidden layer so  $z_1[1]$ will be the output of first node of hidden layer , $z_1[2]$ the output of second node of hidden layer and so on. $a_i$ is the output of layer $i$ after applying the activation function, it forms a vector similar to $z_i$ and the values are tranformed from $z_i$ using an activation function.\\\n",
    "$W_1, b_1, W_2, b_2$ are parameters of the network, which are needed to learn from the training data. You can think of them as matrices transforming data between layers of the network. Looking at the matrix multiplications above you can figure out the dimensionality of these matrices. If 500 nodes are used for the hidden layer then $W_1 \\in \\mathbb{R}^{2\\times500}$, $b_1 \\in \\mathbb{R}^{500}$, $W_2 \\in \\mathbb{R}^{500\\times2}$, $b_2 \\in \\mathbb{R}^{2}$. Now you see why you'll have more parameters if we increase the size of the hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.5` Shapes of all the Vectors\n",
    "\n",
    "Understand that all the variables like weight factors, bias , input x etc are all vectors. Vectorization is done to ease out processes like element wise multiplication and then its summation which would generally require a for loop but with a vectorization a simple dot product would suffice thus increasing the speed and also conveneient and short to code. \n",
    "With neural networks , understanding the shapes of all the parameters is very important so lets look at the shapes :\n",
    "\n",
    "Here , number of training examples are $m$=200 and **n_hid** is the number of nodes in hidden layer\n",
    "1. $X$ has a shape of `(m,2)` : 2 is for the number of attributes i.e $x_1$ and $x_2$ \n",
    "2. $W_1$ has a shape of `(2,n_hid)` connecting each node of input layer and hidden layer and giving them weights : 2 is for the number of attributes i.e $x_1$ and $x_2$ \n",
    "3. $b_1$ has a shape of `(1,n_hid)` as there is one bias for each node in the hidden layer \n",
    "4. $W_2$ has a shape of `(n_hid,2)` connecting each node from hidden layer to the output layer of 2 : 2 is for the output layer giving probabilities of `male` and `female`\n",
    "5. $b_2$ has a shape of `(1,2)` as there is one bias for each node in the output layer thus 2 for 2 nodes (`male` and `female` probabilities) \n",
    "6. $z_1$ has a shape of `(1,n_hid)` as it gives one output for each node and it does that $m$ such instances\n",
    "7. $a_1$ has a shape of `(1,n_hid)` same as $z_1$ as only values inside are changed and not the shape\n",
    "8. $ \\hat{y}$ has a shape of `(1,2)` as its the final output and it has 2 probability values for each of **m** instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.6` Back Propagation : Learning the Parameters \n",
    "\n",
    "Learning the parameters for the network means finding parameters ($W_1, b_1, W_2, b_2$) that minimize the error on the training data. But how to define the error? Especially for that a function that measures our error the loss function is called. Negative log neighbourhood would be used here . If you have $N$ training examples and $C$ classes then the loss for our prediction $\\hat{y}$ with respect to the true labels $y$ is given by:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "H(y,p) = - \\sum_i y_i log(p_i)\n",
    "\\end{aligned}\n",
    "$$\n",
    "The formula looks complicated, but all it really does is sum over our training examples and the $p_{i}$ are the probabilities of the correct classes. So, the further away $y$ (the correct labels) and $\\hat{y}$ (our predictions) are, the greater the loss will be. **Understand that if $p_{i}$ is the probability of the correct classes then $\\hat{y}$ will always be equal to one. So this would be just summation of negative log of probabilities of the correct classes.**\n",
    "\n",
    "Remember that the goal is to find the parameters that minimize the loss function. You can use gradient descent to find its minimum. Here the most basic version of Gradient Descent, also called batch gradient descent with a fixed learning rate is implemented.  Variations such as SGD (stochastic gradient descent) or minibatch gradient descent typically perform better in practice. So if you are serious you'll want to use one of these, and ideally you would also decay the learning rate over time but for now you can use this. \n",
    "\n",
    "As an input, gradient descent needs the gradients (vector of derivatives) of the loss function with respect to the parameters: $\\frac{\\partial{L}}{\\partial{W_1}}$, $\\frac{\\partial{L}}{\\partial{b_1}}$, $\\frac{\\partial{L}}{\\partial{W_2}}$, $\\frac{\\partial{L}}{\\partial{b_2}}$. To calculate these gradients following formulas can be used, \n",
    "\n",
    "Applying the backpropagation formula ,the following results are obtained :\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\delta_3 = \\hat{y} - y \\\\\n",
    "\\delta_2 = (1 - \\tanh^2z_1) \\circ \\delta_3W_2^T \\\\\n",
    "\\frac{\\partial{L}}{\\partial{W_2}} = a_1^T \\delta_3  \\\\\n",
    "\\frac{\\partial{L}}{\\partial{b_2}} = \\delta_3\\\\\n",
    "\\frac{\\partial{L}}{\\partial{W_1}} = x^T \\delta_2\\\\\n",
    "\\frac{\\partial{L}}{\\partial{b_1}} = \\delta_2 \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$T$ signifies transpose of that matrix/vector. \n",
    "**NOTE : in $\\delta_3$ , $y$ would always be equal to 1 if $\\hat{y}$ are the probabilities of the correct classes. So in the code its better to find the probabilities of the right classes and then subtract it by 1** \n",
    "A More in-depth and better understanding can be given [here](https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.7` Differentiations :\n",
    "\n",
    "The Softmax differentiation with the cross entropy loss can be given as : \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "L &= - \\sum_i y_i log(p_i) \\\\\n",
    "\\frac{\\partial L}{\\partial o_i} &= - \\sum_k y_k \\frac{\\partial log(p_k)}{\\partial o_i } \\\\\n",
    "&= - \\sum_k y_k \\frac{\\partial log(p_k)}{\\partial p_k} \\times \\frac{\\partial p_k}{ \\partial o_i} \\\\\n",
    "&= - \\sum y_k \\frac{1}{p_k} \\times \\frac{\\partial p_k}{\\partial o_i} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "With the softmax derivative : \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial L}{\\partial o_i}  &= -y_i(1-p_i) - \\sum_{k\\neq i} y_k \\frac{1}{p_k}(-p_k.p_i) \\\\\n",
    "&= -y_i(1-p_i) + \\sum_{k \\neq 1} y_k.p_i \\\\\n",
    "&= - y_i + y_ip_i + \\sum_{k \\neq 1} y_k.p_i \\\\\n",
    "&= p_i\\left( y_i +  \\sum_{k \\neq 1} y_k\\right) - y_i \\\\\n",
    "&= p_i\\left( y_i +  \\sum_{k \\neq 1} y_k\\right)  - y_i\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$y$ is a one hot encoded vector for the labels, so $\\sum_k y_k = 1$ and $y_i +  \\sum_{k \\neq 1} y_k = 1$ , Thus simplifying it into :\\\n",
    "\n",
    "$\\frac{\\partial L}{\\partial o_i} = p_i - y_i$ which is the same as $\\delta_3 = p_i - y_i$\n",
    "\n",
    "A much more intensive and indepth explanation can be provided [here](https://deepnotes.io/softmax-crossentropy) and [here](https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/)\n",
    "\n",
    "**Forward and backward propagation can be understood with the help of following schematics** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For single node :**\n",
    "\n",
    "<img src=\"https://i.stack.imgur.com/WWJRk.png\" width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For multiple :**\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/6216/1*6q2Rgd8W9DoCN9Wfwc_9gw.png\" width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**These derivatives are calculated , multiplied by learning rate and then added to the weights so as these gradients tend to zero that is error is minimum, the final optimum weights are obtained**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT** : In the following section the terms $dW1$ , $dW2$ , $db1$ ... etc are short forms of $\\frac{\\partial{L}}{\\partial{W_1}}$ ,  $\\frac{\\partial{L}}{\\partial{W_2}}$ , $\\frac{\\partial{L}}{\\partial{b_1}}$ ... respectively and always assume the same for other gradient parameters also"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `4.` Implementation : \n",
    "\n",
    "Now , that a proper understanding of neural networks has been obtained , its time to make a model implementing it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre defining constant parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = len(X) # training set size\n",
    "nn_input_dim = 2 # input layer dimensionality\n",
    "nn_output_dim = 2 # output layer dimensionality\n",
    "\n",
    "# Gradient descent parameters (I picked these by hand)\n",
    "epsilon = 0.01 # learning rate for gradient descent\n",
    "reg_lambda = 0.01 # regularization strength\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.1` Model function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK : Build a function to implement the Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function learns parameters for the neural network and returns the model.\n",
    "# - nn_hdim: Number of nodes in the hidden layer\n",
    "# - num_passes: Number of passes through the training data for gradient descent\n",
    "# - print_loss: If True, print the loss every 1000 iterations\n",
    "\n",
    "# One completion of forward and backward pass happens in one pass and you'll be using 20000 such passes\n",
    "\n",
    "### START CODE HERE : (Write code where '#' is given)\n",
    "\n",
    "def build_model(nn_hdim, num_passes=20000, print_loss=False):\n",
    "    \n",
    "    # Initialize the parameters to random values. \n",
    "    # With succesive gradient descents , the model will learn and will keep updating the parameters \n",
    "    np.random.seed(0)\n",
    "    W1 = np.random.randn(nn_input_dim, nn_hdim) / np.sqrt(nn_input_dim)\n",
    "    b1 = np.zeros((1, nn_hdim))\n",
    "    \n",
    "    # Weights are divided by square root of dimensions to somehow normalise the weights and not have very high values\n",
    "    # Seeing the earlier definition , define 'W2' and 'b2' in the same way \n",
    "    # Take help of the earlier section where shapes are defined\n",
    "    W2 = '#'\n",
    "    # Understand that while weight factors cant be randomly assigned to zeros , however biases can. \n",
    "    b2 = '#'\n",
    "\n",
    "    # This is the model to return at the end\n",
    "    model = {}\n",
    "    \n",
    "    # Gradient descent. For each batch...\n",
    "    for i in range(0, num_passes):\n",
    "\n",
    "        ## FORWARD PROPAGATION\n",
    "        z1 = X.dot(W1) + b1\n",
    "        a1 = np.tanh(z1)\n",
    "        \n",
    "        ## Seeing the earlier definition , define 'z2' and find 'probs' using softmax activation instead of tanh\n",
    "        ## Take help of the section where forward propagation formulas are defined\n",
    "        z2 = '#'\n",
    "        exp_scores = '#'\n",
    "        probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "\n",
    "        ## BACK PROPAGATION\n",
    "        delta3 = probs\n",
    "        delta3[range(num_examples), y] -= 1\n",
    "        dW2 = (a1.T).dot(delta3)\n",
    "        db2 = np.sum(delta3, axis=0, keepdims=True)\n",
    "        #keepdims =True keeps the earlier vectors dimensions which is very important\n",
    "        \n",
    "        ## Seeing the earlier definitions , define 'delta2' ,'dW1' ,'db1'\n",
    "        ## Take help of the backward propagation formulas defined in the earlier sections \n",
    "        \n",
    "        delta2 = '#'\n",
    "        dW1 = '#'\n",
    "        db1 = '#'\n",
    "\n",
    "        # Regularisation terms are added (b1 and b2 don't have regularization terms)\n",
    "        dW2 += reg_lambda * W2\n",
    "        dW1 += reg_lambda * W1\n",
    "\n",
    "        # Gradient descent parameter update\n",
    "        W1 += -epsilon * dW1\n",
    "        b1 += -epsilon * db1\n",
    "        \n",
    "        ## Seeing the earlier definitions , define 'W2' , 'b2'\n",
    "        ## Understand how parameters are updated , epsilon is the contant learning rate \n",
    "        W2 = '#'\n",
    "        b2 = '#'\n",
    "        \n",
    "        # Assigning new parameters to the model\n",
    "        model = { 'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2}\n",
    "        \n",
    "        # Optionally print the loss.\n",
    "        # This is expensive because it uses the whole dataset, so don't want to do it too often.\n",
    "        if print_loss and i % 1000 == 0:\n",
    "             print(\"Loss after iteration %i: %f\" %(i, calculate_loss(model)))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now , The neural network is made which takes in input `nn_hdim` which is the number of nodes in hidden layer and returns the model keeping in mind the input and output parameters. The approach of this was to first randomly assign the parameters and with gradient descent , update it until it reaches the minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once model is made , its essential to make a `predict` function to predict the models outputs and then a `calculate_loss` function that calculates the loss between $\\hat{y}$ and $y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.2` Predict function : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK : Make a function `Predict` that takes in model and X as arguments and returns the maximum probabilities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to predict an output (0 or 1)\n",
    "def predict(model, x):\n",
    "    W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2']\n",
    "    \n",
    "    \n",
    "### START CODE HERE ()\n",
    "   \n",
    "     # FORWARD PROPAGATION\n",
    "    ## Write the full steps of forward propagration as before using the updated parameters  \n",
    "    z1 = '#'\n",
    "    a1 = '#'\n",
    "    z2 = '#'\n",
    "    exp_scores = '#'\n",
    "    probs = '#'\n",
    "    \n",
    "### END CODE\n",
    "    return np.argmax(probs, axis=1)\n",
    "# The maximum probabilites are returned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good schematic to understand why the function returns the maximum probability is given below :\n",
    "<img src=\"https://i.imgur.com/hU252jE.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now , that the output probabilites are calculated , The last step remaining is to calculate the loss between $\\hat{y}$ and $y$ using `cross-entropy` function\n",
    "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcQediZV_J9oWckQU6SMM1bwIJUF05pYb3QJQQhJ3t3YoFcax5Ve&usqp=CAU\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remember it can also be written as summation of negative log of the correct class probabilities which will be implemented in the code**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.3` Loss function: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK : Make function to calculate loss between $\\hat{y}$ and $y$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to evaluate the total loss on the dataset\n",
    "def calculate_loss(model):\n",
    "    \n",
    "    ### START CODE HERE \n",
    "    \n",
    "    ## Take parameters 'W1','b1','W2','b2' from 'model'\n",
    "    ## Take help from the previously defined functions to understand how it can be done\n",
    "    \n",
    "    W1, b1, W2, b2 = '#'\n",
    "    \n",
    "    # Forward propagation to calculate our predictions\n",
    "    ## Note : you can also use previously defined function predict instead\n",
    "    \n",
    "    # Write code to get all the parameters using forward propagation formulas\n",
    "    z1 = '#'\n",
    "    a1 = '#'\n",
    "    z2 = '#'\n",
    "    exp_scores = '#'\n",
    "    probs = '#'\n",
    "    \n",
    "    ## Calculating the loss \n",
    "    corect_logprobs = -np.log(probs['#', '#'])\n",
    "    ## Remember the arguments are such that probs[,] gives out probabilities of correct classes similar to p_i in delta3 formula\n",
    "    data_loss = np.sum(corect_logprobs)\n",
    "    \n",
    "    # Adding regulatization term to loss (optional)\n",
    "    \n",
    "    data_loss += reg_lambda/2 * (np.sum(np.square(W1)) + np.sum(np.square(W2)))\n",
    "    return 1./num_examples * data_loss\n",
    "\n",
    "### END CODE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now that all the helper functions and model functions are made its time to implement it**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK : Using `build_model` function, take `nn_hdim=3` and `print_loss=True` and get the model in a variable called `model`** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a model with a 3-dimensional hidden layer\n",
    "### START CODE HERE (~ 1 Line of code)\n",
    "\n",
    "### END CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK : Plot the decision boundary using `plot_decision_boundary` function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decision boundary\n",
    "### START CODE HERE (~ 2 Lines of code)\n",
    "\n",
    "## See the plot_decision_boundary implementation in logistic regression and write the arguments similarly\n",
    "## Use predict function in lambda x : argument \n",
    "## Give title to the plot \n",
    "\n",
    "\n",
    "### END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `5.` Varying the hidden layer size\n",
    "\n",
    "In the example above you made a hidden layer size of 3. Let's now get a sense of how varying the hidden layer size affects the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK : Using a `for_loop` and the functions build above. make models and plot decision boundaries of varying hidden layer sizes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 32))\n",
    "hidden_layer_dimensions = [1, 2, 3, 4, 5, 20, 50]\n",
    "for i, nn_hdim in enumerate(hidden_layer_dimensions):\n",
    "    ### START CODE HERE (FULL CODE)\n",
    "    \n",
    "    ## Use plt.subplots and plt.title to form subplots of different nn_hdim and give them title accordingly\n",
    "    ## Make model using build_model and make plot decision boundary using plot_decision_boundary and predict functions\n",
    "plt.show()\n",
    "\n",
    "    ### END CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `6.` Conclusion \n",
    "\n",
    "After trying out different activation functions with different sizes of hidden layer ,get an idea of why alot of nodes cant be used in a single hidden layer and which activation functions work best . Based on this , make the adjustments and choose the best final model "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
